<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <link rel="stylesheet" href="css/default.css" type="text/css">
    <title>VisionX</title>
</head>
<body>
    <header>
        <h1>Vision<span id="logo">X</span></h1>
        <nav>
            <ul>
                <li><a class="link" href="#problem">Problem</a></li>
                <li><a class="link" href="#solution">Solution</a></li>
                <li><a class="link" href="#videocontainer">Video</a></li>
                <li><a class="link" href="#product">Product</a></li>
                <li><a class="link" href="#app">App</a></li>
                <li><a class="link" href="#interview">Interview</a></li>
            </ul>
            <br>
            <div class="buttons">
                <button id="fontSize" type="button" onclick="cchangefontSize()">Text size: 100%</button>
                <button id="contrast" type="button" onclick="changeColor()">Contrast: Black</button>
            </div>
        </nav>
        <article>
          <p>
            Our company's end goal is to lift the barrier between blind and sighted as much as
            possible and ensuring that any person with any type of vision loss has the opportunity to explore the world.
          </p>
          <p>
            We want to help the visually impaired by developing a pair of technical glasses equipped with cameras and bone
            conducting headphones that can communicate via Bluetooth to an app on the user's phone.
            VisionX is using the familiar shape of a pair of glasses to help the user blend in.
            The device aims to give the user more feedback about the surroundings than a guide dog can.
          </p>
        </article>
        <figure>
            <img src="media/glasses2.jpg" alt="a hand holding up a pair of glasses">
        </figure>
    </header>

    <hr>


    <main>
        <section id="problem">
            <article>
                <h1>The problem</h1>
                <p>
                    <a href="http://www.who.int/news-room/fact-sheets/detail/blindness-and-visual-impairment">
                        The World Health Organization</a>
                    estimates that 217 million people globally live with moderate to severe vision
                    impairment, and 36 million are blind. People with visual impairments,
                    specifically blindness, face a range of environmental, social and
                    technological challenges in their daily lives.
                </p>
                <p>
                  Some of the most demanding challenges include navigating outside
                  environments. With obstacles such as people, moving cars, temporarily
                  closed roads and more. Because of this, many blind and visually
                  impaired individuals need guidance walking outside, either by a
                  sighted human guide or a guide dog.
                </p>

                <p>While guide dogs may prove to
                  be excellent companions by helping with navigating around obstacles
                  and guiding the handler from point A to point B, they may come short
                  on other terms. Dogs are red-green color blind, and therefore cannot
                  reliably guide the user through traffic light intersections. Also,
                  they cannot read and communicate in our written language, so they
                  can’t help with shopping groceries and such. Furthermore, dogs rely
                  heavily on input from the handler.
                </p>
                <p>For example, handlers has to know
                  how to get to their destination by memory and always keep track of
                  where they are, as the dog can’t know how to get to a specific street
                  or place, and can't tell handlers where they are. In other words, the
                  guide dog will guide you around obstacles, but cannot fully replace
                  the benefits of having a human guide. Using a human guide can result
                  in the blind person feeling like a burden to those around them and
                  impact their self esteem, as they’re constantly reminded that they’re
                  dependent on others to do their daily chores.
                </p>
                <p>
                    <a href="https://www.youtube.com/watch?v=ir-Jg0LwenI">Here is a video
                    showing a blind woman and a service dog walking to Starbucks
                    through several intersections.</a> The woman uses her own mental
                    map of where she is, and the dog helps her get to traffic light
                    poles and doors, but she has to rely on her own senses to know
                    when to cross the street.
                </p>
                <p>
                    According to Guide Dogs organisation in the UK, <a href="https://www.guidedogs.org.uk/about-us/how-your-money-is-helping/">the total cost
                    of a guide dog from birth to retirement</a> equates to around
                    <strong>£56,800.</strong> Pricing, in addition to other shortcomings of guide dogs,
                    give rise to the need for a new solution. <br>
                </p>

            </article>
        </section>

        <hr>

        <section id="solution">
            <article>
                <h1>The solution</h1>
                <p>
                    VisionX is our solution for bringing the blind one step closer to
                    feeling independent. VisionX aims to be a fullworthy guide-device,
                    assisting in navigating both indoors and outdoors by a combination
                    of GPS and AI vision with depth mapping, helping with shopping,
                    reading labels, signs and bus tables and much more. The device will
                    be developed in cooperation with it’s target group, which ensure that
                    VisionX is tailor-made for its purpose. Our company's end goal is
                    to lift the barrier between blind and sighted as much as possible
                    and ensuring that any person with any type of vision loss has the
                    opportunity to explore the world.
                </p>
                <p>
                    VisionX is a combination of an app for the users phone, and a pair
                    of camera glasses. The glasses is the users “eyes and ears” and
                    the app is the brains and communication tool. The app and the
                    glasses are connected by bluetooth.
                </p>
                <p>
                    By designing VisionX like a pair of glasses, the user will be able
                    to blend in to his surroundings. In addition to be a familiar shape
                    to a lot of people, It is easy to take on and off, and is not
                    prohibited by any garments.
                </p>
                <p>
                    The app uses location services to locate where the users are and
                    where they’re going. Users can issue commands such as “take me to
                    the grocery store” to get guided navigation optimized for their
                    disability. The software will give a combination of voice guidance
                    and haptic feedback, where voice will be relayed through the embedded
                    bone conducting headphones in the glasses.
                </p>
                <p>
                    The VisionX glasses will constantly send feedback from the two
                    front cameras, placed on each side of the glasses, to the app. The
                    app then uses Google Cloud Vision to interpret what’s in front of
                    the user, and let the user know if there are any obstacles his the pathway.
                </p>
                <p>
                    In addition to helping users navigate,VisionX also have the
                    ability to read text. By pointing on text or objects or giving a
                    voice command, the app will search for text around the finger and
                    use OCR technology to parse text and read it back to the user.
                    This will make it easier for the visually impaired to read bus
                    tables or pricing in the grocery store.
                </p>
            </article>
        </section>

        <hr>

        <section id="videocontainer">

          <h1>Demo video</h1>


          <div id="videoAccessibilityControls">
            <button class = "playerbtn accessOnOff" type="button">Regular controls</button>
          </div>
          <video controls id="video1"src="media/demovideo.mp4">
            <track src="SubtitlesEng.vtt" kind="subtitles" srclang="en" label="English" >
              <p>Your browser does not support HTML5 video.</p>
              <p>The video shows how VisionX will detect obstacles, cars and crosswalks</p>
            </video>

            <div id="videoControls">
              <button class="playerbtn playpause" type="button">Play</button>
              <button Class="playerbtn stop" type="button">Stop</button>
              <button class="playerbtn restart" type="button">Restart</button>
              <button class="playerbtn subtitles">Turn on subtitles</button>
              <button class="playerbtn transcript">Show video trancript</button>
            </div>

            <article id="videoTranscript">
              <h2>Transcript</h2>
              <p>
                The video demonstrates how the camera scans the surroundings and the
                system recognize a crosswalk or an obstacle and notifies the user.
              </p>
              <p>
                The first part shows a picure of a crosswalk being scanned by a
                red line. After the red line scans the image, "approaching crosswalk"
                is read aloud by a female voice.
              </p>
              <p>
                The second image shows an image of a sidewalk, where a beam is in the
                way. The same red line scans the image. Here you can see the depth in the
                image as it scans over, and the beam is marked in red before "obstacle, turn
                left" is read aloud.
              </p>
              <p>
                The last image shows a crosswalk and a car. As the image is scanned, the
                car is marked in red, and "vehicle approaching" is read aloud.
              </p>
            </article>

          </section>

          <hr>

        <section id="product">
            <article>
                <h1>How it works</h1>
                <p>
                    VisionX are smart glasses outfitted with two depth sensing
                    cameras. The cameras scans the surroundings and sends the
                    video to the users smartphone via Bluetooth. They are seamlessly
                    integrated on each side on the glasses end piece.
                </p>
                <p>
                    The video sent to the smartphone is processed with an app
                    we provide that uses AI-image recognition to relay information
                    about the path ahead. By using google's Cloud Vision the user is
                    not limited to only iPhones. The app is supported on android 4.4+
                    and iOS 11.0+. The phone also uses it’s built in GPS to keep
                    track of the users position.
                </p>
                <p>
                    VisionX are equipped with haptic feedback drives located in
                    the temples along side the batteries. When the user starts to
                    veer off course, approaches an intersection or any obstacle,
                    the glasses vibrates and notifies the user vocally. Either on
                    the left side to indicate to the user to correct towards right
                    and vice versa.
                </p>
                <img src="media/glasses4.jpg" alt="a pair of glasses upside down on a book">
                <p>
                    When the user approaches an intersection the glasses vibrates
                    on both sides at an increasing rate until it vibrates constantly
                    and a message is read “approaching crosswalk”. The vibration stops
                    when its clear to cross and a message reads out “crosswalk clear”.
                    When the user approaches an obstacle the same vibration pattern is
                    followed but a different message is read “obstacle” followed by turn
                    either “left” or “right” accordingly.
                </p>
                <p>
                    Instead of relying on the user to wear earphones or outfitting
                    the glasses with speakers, the glass has built in bone conducting
                    headphones. These are located at the back of the temples.
                    This transmits sound to user only, without interfering with
                    surrounding sounds from approaching cars, etc.
                </p>
                <p>
                    To help the user read text, the user simply points with the
                    index finger and the glasses use OCR (optical character recognition)
                    technology to parse text and read what it can find near the finger.
                    By combining OCR and Cloud vision, VisionX can also detect specific
                    objects such as money and their associated value and credit card
                    information.
                </p>
            </article>
        </section>

        <hr>

        <section id="app">
            <article>
                <h1>The app</h1>
                <p>
                The picture illustrates a simple mockup of the app the user interacts with.
                Here, the user can customize the features.
                </p>
                <p>
                More specifically:
                Check if the glasses are connected. If not, perform connection.
                Turn on and off the navigation and add favorite places such as home, and frequently visited stores.
                </p>
                <p>
                Enable or disable object identification. Increase, reduce or turn off the haptic feedback drive.
                Turn on or off collision detection. The “other” section includes options for the battery and
                various settings for the bone conducting headphones.
                </p>
            </article>
            <figure>
                <img src="media/appMockup.png" alt="Illustration of the app. At the top, in the middle,
                is the name of user and to the right is the log out button. Underneath, on the left,
                is the name of the setting and on the right is status of the setting.
                Beside the status is an arrow pointing to the right to indicate that the user can click on each item.
                From the top to bottom it reads: Glasses, Navigation, Object Identification, Haptic feedback, Collision detection and Other.">
            </figure>
        </section>

        <hr>

        <section id="interview">
          <article>
            <h1>Interview</h1>
            <p>
              “I don’t see the world as good as other people. I can’t see the birds in the sky or the
              details in the landscape. I think that’s the most annoying things in my daily life.”, says
              a visually challenged man that wants to be anonymous. He is a 27 years old and lives in Oslo
              with a condition named Keratoconus that makes his cornea's central part bend forward.
            </p>
            <p>
              People with Keratoconus are often born with normal corneas, but the condition often worsen
              when the patient is in his teens. According to a study published by <a href="https://www.ajo.com/article/S0002-9394(16)30613-4/fulltext"> American Journal of
              Ophthalmology</a> i 2017, Keratoconus occur in 1 to 375 people in the Netherlands.
            </p>
            <p>
              When asked a question about what challenges he faces in his everyday life, he says: “I can't
              really read signs properly. I struggle with reading newspaper and books without lenses. There is
              obstacles on every level. It worries me that I can’t do what I want because of my sight.”
            </p>
            <br>
            <h2>Lessen the differences</h2>
            <p>
              Today the only solution for him is hard lenses or glasses. According to <a href="https://www.blindeforbundet.no/oyehelse-og-synshemninger/keratokonus-kc">Norges blindeforbund</a> a
              lot of people with Keratoconus struggle with the ability to use the lenses all day, and some
              people even develop contact lens intolerance. Constantly readjusting the lenses can often lead
              to irritation on the eye.
            </p>
            <p>
              We talk a little bit about VisonX, and it becomes clear that he believes the future is in
              technology. “I think we can use technology to lessen the difference between visually impaired
              and sighted people, there is only so much you can do without it. From the ticking in traffic
              lights to the voice on the bus, we have to keep on evolving our technology and grow together
              as one society.”
            </p>


        </article></section>
    </main>
    <footer><a href="#top">Back to top of page</a></footer>
    <script src="javascript/buttons.js"></script>
    <script src="javascript/videocontroller.js"></script>
</body>
</html>
